{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"csi-gcs \u00b6 CI/CD Docs Image Meta An easy-to-use, cross-platform, and highly optimized Kubernetes CSI driver for mounting Google Cloud Storage buckets. License \u00b6 csi-gcs is distributed under the terms of both Apache License, Version 2.0 MIT License at your option. Navigation \u00b6 Desktop readers can use keyboard shortcuts to navigate. Keys Action , (comma) p Navigate to the \"previous\" page . (period) n Navigate to the \"next\" page / s Display the search modal","title":"About"},{"location":"#license","text":"csi-gcs is distributed under the terms of both Apache License, Version 2.0 MIT License at your option.","title":"License"},{"location":"#navigation","text":"Desktop readers can use keyboard shortcuts to navigate. Keys Action , (comma) p Navigate to the \"previous\" page . (period) n Navigate to the \"next\" page / s Display the search modal","title":"Navigation"},{"location":"csi_compatibility/","text":"CSI Specification Compatibility \u00b6 This page describes compatibility to the CSI specification . Capacity \u00b6 Important Google Cloud Storage has no concept of capacity limits. Therefore, this driver is unable to provide capacity limit enforcement. The driver only sets a capacity label for the bucket containing the requested bytes. Snapshots \u00b6 Snapshots are not currently supported, but are on the roadmap for the future. CreateVolume / VolumeContentSource \u00b6 CreateVolume / VolumeContentSource is not currently supported, but is on the roadmap for the future. Fuse \u00b6 Since gcsfuse is backed by fuse , the mount needs a process to back it. This is an unsolved problem with CSI . See kubernetes/kubernetes#70013 Because of this problem, all mounts will terminate if a pod of the csi-gcs-node DaemonSet is restarted. This for example happens when the driver is updated. To counteract the problem of having pods with broken mounts, the csi-gcs-node Pod will terminate all Pods with broken mounts on start. Disabling Pod Termination The Pod Termination can be disabled by changing the argument delete-orphaned-pods to false on the DaemonSet.","title":"CSI Compatibility"},{"location":"csi_compatibility/#capacity","text":"Important Google Cloud Storage has no concept of capacity limits. Therefore, this driver is unable to provide capacity limit enforcement. The driver only sets a capacity label for the bucket containing the requested bytes.","title":"Capacity"},{"location":"csi_compatibility/#snapshots","text":"Snapshots are not currently supported, but are on the roadmap for the future.","title":"Snapshots"},{"location":"csi_compatibility/#createvolume-volumecontentsource","text":"CreateVolume / VolumeContentSource is not currently supported, but is on the roadmap for the future.","title":"CreateVolume / VolumeContentSource"},{"location":"csi_compatibility/#fuse","text":"Since gcsfuse is backed by fuse , the mount needs a process to back it. This is an unsolved problem with CSI . See kubernetes/kubernetes#70013 Because of this problem, all mounts will terminate if a pod of the csi-gcs-node DaemonSet is restarted. This for example happens when the driver is updated. To counteract the problem of having pods with broken mounts, the csi-gcs-node Pod will terminate all Pods with broken mounts on start. Disabling Pod Termination The Pod Termination can be disabled by changing the argument delete-orphaned-pods to false on the DaemonSet.","title":"Fuse"},{"location":"dynamic_provisioning/","text":"Dynamic provisioning \u00b6 Secrets \u00b6 After acquiring service account keys , create 2 secrets (we'll call them csi-gcs-secret-mounter and csi-gcs-secret-creator in the following example): kubectl create secret generic csi-gcs-secret-mounter --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY_1> kubectl create secret generic csi-gcs-secret-creator --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY_2> --from-literal=projectId=csi-gcs Usage \u00b6 Let's run another example application! kubectl apply -k \"github.com/ofek/csi-gcs/examples/dynamic?ref=v0.9.0\" Confirm it's working by running kubectl get pods,sc,pv,pvc You should see something like NAME READY STATUS RESTARTS AGE pod/csi-gcs-test-5f677df9f9-qd8nt 2/2 Running 0 100s NAME PROVISIONER AGE storageclass.storage.k8s.io/csi-gcs gcs.csi.ofek.dev 100s NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pvc-906ed812-2c06-4eaa-a80e-7115e8ffd653 5Gi RWO Delete Bound default/csi-gcs-pvc csi-gcs 98s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/csi-gcs-pvc Bound pvc-906ed812-2c06-4eaa-a80e-7115e8ffd653 5Gi RWO csi-gcs 100s Note the pod name, in this case csi-gcs-test-5f677df9f9-qd8nt . The pod in the example deployment has 2 containers: a writer and a reader . Now create some data! kubectl exec csi-gcs-test-5f677df9f9-qd8nt -c writer -- /bin/sh -c \"echo Hello from Google Cloud Storage! > /data/test.txt\" Let's read what we just put in the bucket $ kubectl exec csi-gcs-test-5f677df9f9-qd8nt -c reader -it -- /bin/sh / # ls -lh /data total 1K -rw-r--r-- 1 root root 33 May 26 21:23 test.txt / # cat /data/test.txt Hello from Google Cloud Storage! Notice that while the writer container's permission is completely governed by the mounter 's service account key, the reader container is further restricted to read-only access / # touch /data/forbidden.txt touch: /data/forbidden.txt: Read-only file system To clean up everything, run the following commands kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/deployment.yaml\" kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/pvc.yaml\" kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/sc.yaml\" kubectl delete -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" kubectl delete secret csi-gcs-secret-creator kubectl delete secret csi-gcs-secret-mounter Note Cleanup is necessarily verbose until this is resolved. Driver options \u00b6 StorageClass is the resource type that enables dynamic provisioning. apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : <STORAGE_CLASS_NAME> provisioner : gcs.csi.ofek.dev reclaimPolicy : Delete parameters : ... Storage Class Parameters \u00b6 Annotation Description csi.storage.k8s.io/node-publish-secret-name The name of the secret allowed to mount created buckets csi.storage.k8s.io/node-publish-secret-namespace The namespace of the secret allowed to mount created buckets csi.storage.k8s.io/provisioner-secret-name The name of the secret allowed to create buckets csi.storage.k8s.io/provisioner-secret-namespace The namespace of the secret allowed to create buckets csi.storage.k8s.io/controller-expand-secret-name The name of the secret allowed to expand bucket capacity csi.storage.k8s.io/controller-expand-secret-namespace The namespace of the secret allowed to expand bucket capacity gcs.csi.ofek.dev/project-id The project to create the buckets in. If not specified, projectId will be looked up in the provisioner's secret gcs.csi.ofek.dev/location The location to create buckets at (default US multi-region) gcs.csi.ofek.dev/kms-key-id (optional) KMS encryption key ID. (projects/my-pet-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key) gcs.csi.ofek.dev/max-retry-sleep The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. Tip You may omit the secret definition and let the code automatically detect the service account key using standard heuristics . Persistent Volume Claim Parameters \u00b6 apiVersion : v1 kind : PersistentVolumeClaim metadata : annotations : ... Annotation Description gcs.csi.ofek.dev/project-id The project to create the buckets in. If not specified, projectId will be looked up in the provisioner's secret gcs.csi.ofek.dev/location The location to create buckets at (default US multi-region) gcs.csi.ofek.dev/bucket The name for the new bucket gcs.csi.ofek.dev/kms-key-id (optional) KMS encryption key ID. (projects/my-pet-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key) gcs.csi.ofek.dev/max-retry-sleep The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. Persistent buckets \u00b6 In our example, the dynamically created buckets are deleted during cleanup. If you want the buckets to not be ephemeral, you can set reclaimPolicy to Retain . Extra flags \u00b6 You can pass flags to gcsfuse . They will be forwarded to PersistentVolumeClaim.spec.csi.volumeAttributes . The following flags are supported (ordered by precedence): PersistentVolumeClaim.metadata.annotations apiVersion : v1 kind : PersistentVolumeClaim metadata : annotations : gcs.csi.ofek.dev/gid : \"63147\" gcs.csi.ofek.dev/dir-mode : \"0775\" gcs.csi.ofek.dev/file-mode : \"0664\" Option Type Description gcs.csi.ofek.dev/dir-mode Octal Integer Permission bits for directories. (default: 0775) gcs.csi.ofek.dev/file-mode Octal Integer Permission bits for files. (default: 0664) gcs.csi.ofek.dev/gid Integer GID owner of all inodes. (default: 63147) gcs.csi.ofek.dev/uid Integer UID owner of all inodes. (default: -1) gcs.csi.ofek.dev/implicit-dirs Flag Implicitly define directories based on content. gcs.csi.ofek.dev/billing-project Text Project to use for billing when accessing requester pays buckets. gcs.csi.ofek.dev/limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). gcs.csi.ofek.dev/limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. gcs.csi.ofek.dev/stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . gcs.csi.ofek.dev/type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . gcs.csi.ofek.dev/fuse-mount-options Text[] Additional comma-separated system-specific mount options . Be careful! gcs.csi.ofek.dev/max-retry-sleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.parameters apiVersion : storage.k8s.io/v1 kind : StorageClass parameters : gid : \"63147\" dirMode : \"0775\" fileMode : \"0664\" Option Type Description dirMode Octal Integer Permission bits for directories. (default: 0775) fileMode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! maxRetrySleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.mountOptions apiVersion : storage.k8s.io/v1 kind : StorageClass mountOptions : - --gid=63147 - --dir-mode=0775 - --file-mode=0664 Option Type Description dir-mode Octal Integer Permission bits for directories. (default: 0775) file-mode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicit-dirs Flag Implicitly define directories based on content. billing-project Text Project to use for billing when accessing requester pays buckets. limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuse-mount-option Text Additional system-specific mount option . Be careful! max-retry-sleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.parameters.\"csi.storage.k8s.io/provisioner-secret-name \" Option Type Description dirMode Octal Integer Permission bits for directories, in octal. (default: 0775) fileMode Octal Integer Permission bits for files, in octal. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! maxRetrySleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. Permission \u00b6 In order to access anything stored in GCS , you will need service accounts with appropriate IAM roles. You will usually assign the role roles/storage.admin . The easiest way to create service account keys, if you don't yet have any, is to run: gcloud iam service-accounts list to find the email of a desired service account, then run: gcloud iam service-accounts keys create <FILE_NAME>.json --iam-account <EMAIL> to create a key file. Mounter \u00b6 The Node Plugin is the component that is actually mounting and serving buckets to pods. If writes are needed, you will usually select roles/storage.objectAdmin scoped to the desired buckets. Creator \u00b6 The Controller Plugin is the component that is in charge of creating buckets. The service account will need the storage.buckets.create Cloud IAM permission .","title":"Dynamic provisioning"},{"location":"dynamic_provisioning/#secrets","text":"After acquiring service account keys , create 2 secrets (we'll call them csi-gcs-secret-mounter and csi-gcs-secret-creator in the following example): kubectl create secret generic csi-gcs-secret-mounter --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY_1> kubectl create secret generic csi-gcs-secret-creator --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY_2> --from-literal=projectId=csi-gcs","title":"Secrets"},{"location":"dynamic_provisioning/#usage","text":"Let's run another example application! kubectl apply -k \"github.com/ofek/csi-gcs/examples/dynamic?ref=v0.9.0\" Confirm it's working by running kubectl get pods,sc,pv,pvc You should see something like NAME READY STATUS RESTARTS AGE pod/csi-gcs-test-5f677df9f9-qd8nt 2/2 Running 0 100s NAME PROVISIONER AGE storageclass.storage.k8s.io/csi-gcs gcs.csi.ofek.dev 100s NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pvc-906ed812-2c06-4eaa-a80e-7115e8ffd653 5Gi RWO Delete Bound default/csi-gcs-pvc csi-gcs 98s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/csi-gcs-pvc Bound pvc-906ed812-2c06-4eaa-a80e-7115e8ffd653 5Gi RWO csi-gcs 100s Note the pod name, in this case csi-gcs-test-5f677df9f9-qd8nt . The pod in the example deployment has 2 containers: a writer and a reader . Now create some data! kubectl exec csi-gcs-test-5f677df9f9-qd8nt -c writer -- /bin/sh -c \"echo Hello from Google Cloud Storage! > /data/test.txt\" Let's read what we just put in the bucket $ kubectl exec csi-gcs-test-5f677df9f9-qd8nt -c reader -it -- /bin/sh / # ls -lh /data total 1K -rw-r--r-- 1 root root 33 May 26 21:23 test.txt / # cat /data/test.txt Hello from Google Cloud Storage! Notice that while the writer container's permission is completely governed by the mounter 's service account key, the reader container is further restricted to read-only access / # touch /data/forbidden.txt touch: /data/forbidden.txt: Read-only file system To clean up everything, run the following commands kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/deployment.yaml\" kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/pvc.yaml\" kubectl delete -f \"https://github.com/ofek/csi-gcs/blob/v0.9.0/examples/dynamic/sc.yaml\" kubectl delete -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" kubectl delete secret csi-gcs-secret-creator kubectl delete secret csi-gcs-secret-mounter Note Cleanup is necessarily verbose until this is resolved.","title":"Usage"},{"location":"dynamic_provisioning/#driver-options","text":"StorageClass is the resource type that enables dynamic provisioning. apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : <STORAGE_CLASS_NAME> provisioner : gcs.csi.ofek.dev reclaimPolicy : Delete parameters : ...","title":"Driver options"},{"location":"dynamic_provisioning/#storage-class-parameters","text":"Annotation Description csi.storage.k8s.io/node-publish-secret-name The name of the secret allowed to mount created buckets csi.storage.k8s.io/node-publish-secret-namespace The namespace of the secret allowed to mount created buckets csi.storage.k8s.io/provisioner-secret-name The name of the secret allowed to create buckets csi.storage.k8s.io/provisioner-secret-namespace The namespace of the secret allowed to create buckets csi.storage.k8s.io/controller-expand-secret-name The name of the secret allowed to expand bucket capacity csi.storage.k8s.io/controller-expand-secret-namespace The namespace of the secret allowed to expand bucket capacity gcs.csi.ofek.dev/project-id The project to create the buckets in. If not specified, projectId will be looked up in the provisioner's secret gcs.csi.ofek.dev/location The location to create buckets at (default US multi-region) gcs.csi.ofek.dev/kms-key-id (optional) KMS encryption key ID. (projects/my-pet-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key) gcs.csi.ofek.dev/max-retry-sleep The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. Tip You may omit the secret definition and let the code automatically detect the service account key using standard heuristics .","title":"Storage Class Parameters"},{"location":"dynamic_provisioning/#persistent-volume-claim-parameters","text":"apiVersion : v1 kind : PersistentVolumeClaim metadata : annotations : ... Annotation Description gcs.csi.ofek.dev/project-id The project to create the buckets in. If not specified, projectId will be looked up in the provisioner's secret gcs.csi.ofek.dev/location The location to create buckets at (default US multi-region) gcs.csi.ofek.dev/bucket The name for the new bucket gcs.csi.ofek.dev/kms-key-id (optional) KMS encryption key ID. (projects/my-pet-project/locations/us-east1/keyRings/my-key-ring/cryptoKeys/my-key) gcs.csi.ofek.dev/max-retry-sleep The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries.","title":"Persistent Volume Claim Parameters"},{"location":"dynamic_provisioning/#persistent-buckets","text":"In our example, the dynamically created buckets are deleted during cleanup. If you want the buckets to not be ephemeral, you can set reclaimPolicy to Retain .","title":"Persistent buckets"},{"location":"dynamic_provisioning/#extra-flags","text":"You can pass flags to gcsfuse . They will be forwarded to PersistentVolumeClaim.spec.csi.volumeAttributes . The following flags are supported (ordered by precedence): PersistentVolumeClaim.metadata.annotations apiVersion : v1 kind : PersistentVolumeClaim metadata : annotations : gcs.csi.ofek.dev/gid : \"63147\" gcs.csi.ofek.dev/dir-mode : \"0775\" gcs.csi.ofek.dev/file-mode : \"0664\" Option Type Description gcs.csi.ofek.dev/dir-mode Octal Integer Permission bits for directories. (default: 0775) gcs.csi.ofek.dev/file-mode Octal Integer Permission bits for files. (default: 0664) gcs.csi.ofek.dev/gid Integer GID owner of all inodes. (default: 63147) gcs.csi.ofek.dev/uid Integer UID owner of all inodes. (default: -1) gcs.csi.ofek.dev/implicit-dirs Flag Implicitly define directories based on content. gcs.csi.ofek.dev/billing-project Text Project to use for billing when accessing requester pays buckets. gcs.csi.ofek.dev/limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). gcs.csi.ofek.dev/limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. gcs.csi.ofek.dev/stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . gcs.csi.ofek.dev/type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . gcs.csi.ofek.dev/fuse-mount-options Text[] Additional comma-separated system-specific mount options . Be careful! gcs.csi.ofek.dev/max-retry-sleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.parameters apiVersion : storage.k8s.io/v1 kind : StorageClass parameters : gid : \"63147\" dirMode : \"0775\" fileMode : \"0664\" Option Type Description dirMode Octal Integer Permission bits for directories. (default: 0775) fileMode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! maxRetrySleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.mountOptions apiVersion : storage.k8s.io/v1 kind : StorageClass mountOptions : - --gid=63147 - --dir-mode=0775 - --file-mode=0664 Option Type Description dir-mode Octal Integer Permission bits for directories. (default: 0775) file-mode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicit-dirs Flag Implicitly define directories based on content. billing-project Text Project to use for billing when accessing requester pays buckets. limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuse-mount-option Text Additional system-specific mount option . Be careful! max-retry-sleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries. StorageClass.parameters.\"csi.storage.k8s.io/provisioner-secret-name \" Option Type Description dirMode Octal Integer Permission bits for directories, in octal. (default: 0775) fileMode Octal Integer Permission bits for files, in octal. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! maxRetrySleep Integer The maximum duration allowed to sleep in a retry loop with exponential backoff for failed requests to GCS backend. Once the backoff duration exceeds this limit, the retry stops. The default is 1 minute. A value of 0 disables retries.","title":"Extra flags"},{"location":"dynamic_provisioning/#permission","text":"In order to access anything stored in GCS , you will need service accounts with appropriate IAM roles. You will usually assign the role roles/storage.admin . The easiest way to create service account keys, if you don't yet have any, is to run: gcloud iam service-accounts list to find the email of a desired service account, then run: gcloud iam service-accounts keys create <FILE_NAME>.json --iam-account <EMAIL> to create a key file.","title":"Permission"},{"location":"dynamic_provisioning/#mounter","text":"The Node Plugin is the component that is actually mounting and serving buckets to pods. If writes are needed, you will usually select roles/storage.objectAdmin scoped to the desired buckets.","title":"Mounter"},{"location":"dynamic_provisioning/#creator","text":"The Controller Plugin is the component that is in charge of creating buckets. The service account will need the storage.buckets.create Cloud IAM permission .","title":"Creator"},{"location":"getting_started/","text":"Getting started \u00b6 Installation \u00b6 Like other CSI drivers, a StatefulSet and DaemonSet are the recommended deployment mechanisms for the Controller Plugin and Node Plugin , respectively. Run kubectl apply -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" Now the output from running the command kubectl get CSIDriver,daemonsets,pods -n kube-system should contain something like NAME CREATED AT csidriver.storage.k8s.io/gcs.csi.ofek.dev 2020-05-26T21:03:14Z NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/csi-gcs 1 1 1 1 1 kubernetes.io/os=linux 18s NAME READY STATUS RESTARTS AGE pod/csi-gcs-f9vgd 4/4 Running 0 18s Customer-managed encryption keys (CMEK) \u00b6 Make sure that your Google Cloud Storage service account has roles/cloudkms.cryptoKeyEncrypterDecrypter for the target encryption key. kmsKeyId / gcs.csi.ofek.dev/kms-key-id could be defined as part of a secret or annotation/mount to enable CMEK encryption for Google Storage . Debugging \u00b6 kubectl logs -l app=csi-gcs -c csi-gcs -n kube-system Resource Requests / Limits \u00b6 To change the default resource requests & limits, override them using kustomize. kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization bases : - github.com/ofek/csi-gcs/deploy/overlays/stable-gke?ref=v0.9.0 patchesStrategicMerge : - resources.yaml resources.yaml apiVersion : apps/v1 kind : DaemonSet metadata : name : csi-gcs spec : template : spec : containers : - name : csi-gcs resources : limits : cpu : 1 memory : 1Gi requests : cpu : 10m memory : 80Mi Namespace \u00b6 This driver deploys directly into the kube-system namespace. That can't be changed since the DaemonSet requires priorityClassName: system-node-critical to be prioritized over normal workloads.","title":"Getting started"},{"location":"getting_started/#installation","text":"Like other CSI drivers, a StatefulSet and DaemonSet are the recommended deployment mechanisms for the Controller Plugin and Node Plugin , respectively. Run kubectl apply -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" Now the output from running the command kubectl get CSIDriver,daemonsets,pods -n kube-system should contain something like NAME CREATED AT csidriver.storage.k8s.io/gcs.csi.ofek.dev 2020-05-26T21:03:14Z NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/csi-gcs 1 1 1 1 1 kubernetes.io/os=linux 18s NAME READY STATUS RESTARTS AGE pod/csi-gcs-f9vgd 4/4 Running 0 18s","title":"Installation"},{"location":"getting_started/#customer-managed-encryption-keys-cmek","text":"Make sure that your Google Cloud Storage service account has roles/cloudkms.cryptoKeyEncrypterDecrypter for the target encryption key. kmsKeyId / gcs.csi.ofek.dev/kms-key-id could be defined as part of a secret or annotation/mount to enable CMEK encryption for Google Storage .","title":"Customer-managed encryption keys (CMEK)"},{"location":"getting_started/#debugging","text":"kubectl logs -l app=csi-gcs -c csi-gcs -n kube-system","title":"Debugging"},{"location":"getting_started/#resource-requests-limits","text":"To change the default resource requests & limits, override them using kustomize. kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization bases : - github.com/ofek/csi-gcs/deploy/overlays/stable-gke?ref=v0.9.0 patchesStrategicMerge : - resources.yaml resources.yaml apiVersion : apps/v1 kind : DaemonSet metadata : name : csi-gcs spec : template : spec : containers : - name : csi-gcs resources : limits : cpu : 1 memory : 1Gi requests : cpu : 10m memory : 80Mi","title":"Resource Requests / Limits"},{"location":"getting_started/#namespace","text":"This driver deploys directly into the kube-system namespace. That can't be changed since the DaemonSet requires priorityClassName: system-node-critical to be prioritized over normal workloads.","title":"Namespace"},{"location":"static_provisioning/","text":"Static provisioning \u00b6 Secrets \u00b6 After acquiring a service account key , create a secret (we'll call it csi-gcs-secret in the following example): kubectl create secret generic csi-gcs-secret --from-literal=bucket=<BUCKET_NAME> --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY> Note we store the desired bucket in the secret for brevity only, there are other ways to select a bucket. Usage \u00b6 Let's run an example application! kubectl apply -k \"github.com/ofek/csi-gcs/examples/static?ref=v0.9.0\" Confirm it's working by running kubectl get pods,pv,pvc You should see something like NAME READY STATUS RESTARTS AGE pod/csi-gcs-test-5f677df9f9-f59km 2/2 Running 0 10s NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/csi-gcs-pv 5Gi RWO Retain Bound default/csi-gcs-pvc csi-gcs-test-sc 10s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/csi-gcs-pvc Bound csi-gcs-pv 5Gi RWO csi-gcs-test-sc 10s Note the pod name, in this case csi-gcs-test-5f677df9f9-f59km . The pod in the example deployment has 2 containers: a writer and a reader . Now create some data! kubectl exec csi-gcs-test-5f677df9f9-f59km -c writer -- /bin/sh -c \"echo Hello from Google Cloud Storage! > /data/test.txt\" Let's read what we just put in the bucket $ kubectl exec csi-gcs-test-5f677df9f9-f59km -c reader -it -- /bin/sh / # ls -lh /data total 1K -rw-r--r-- 1 root root 33 May 26 21:23 test.txt / # cat /data/test.txt Hello from Google Cloud Storage! Notice that while the writer container's permission is completely governed by the service account key, the reader container is further restricted to read-only access / # touch /data/forbidden.txt touch: /data/forbidden.txt: Read-only file system To clean up everything, run the following commands kubectl delete -k \"github.com/ofek/csi-gcs/examples/static?ref=v0.9.0\" kubectl delete -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" kubectl delete secret csi-gcs-secret Driver options \u00b6 See the CSI section of the Kubernetes Volume docs . Service account key \u00b6 The contents of the JSON key may be passed in as a secret defined in PersistentVolume.spec.csi.nodePublishSecretRef . The name of the key in the secret is key . Tip You may omit the secret definition and let the code automatically detect the service account key using standard heuristics . Bucket \u00b6 The bucket name is resolved in the following order: bucket in PersistentVolume.spec.csi.volumeAttributes bucket in PersistentVolume.spec.mountOptions bucket in secret referenced by PersistentVolume.spec.csi.nodePublishSecretRef PersistentVolume.spec.csi.volumeHandle Extra flags \u00b6 You can pass flags to gcsfuse in the following ways (ordered by precedence): PersistentVolume.spec.csi.volumeAttributes apiVersion : v1 kind : PersistentVolume spec : csi : driver : gcs.csi.ofek.dev volumeAttributes : gid : \"63147\" dirMode : \"0775\" fileMode : \"0664\" Option Type Description dirMode Octal Integer Permission bits for directories. (default: 0775) fileMode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! PersistentVolume.spec.mountOptions apiVersion : v1 kind : PersistentVolume spec : mountOptions : - --gid=63147 - --dir-mode=0775 - --file-mode=0664 Option Type Description dir-mode Octal Integer Permission bits for directories. (default: 0775) file-mode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicit-dirs Flag Implicitly define directories based on content. billing-project Text Project to use for billing when accessing requester pays buckets. limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuse-mount-option Text Additional comma-separated system-specific mount option . Be careful! PersistentVolume.spec.csi.nodePublishSecretRef Option Type Description dirMode Octal Integer Permission bits for directories, in octal. (default: 0775) fileMode Octal Integer Permission bits for files, in octal. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! Permission \u00b6 In order to access anything stored in GCS , you will need service accounts with appropriate IAM roles. If writes are needed, you will usually select roles/storage.objectAdmin scoped to the desired buckets. The easiest way to create service account keys, if you don't yet have any, is to run: gcloud iam service-accounts list to find the email of a desired service account, then run: gcloud iam service-accounts keys create <FILE_NAME>.json --iam-account <EMAIL> to create a key file.","title":"Static provisioning"},{"location":"static_provisioning/#secrets","text":"After acquiring a service account key , create a secret (we'll call it csi-gcs-secret in the following example): kubectl create secret generic csi-gcs-secret --from-literal=bucket=<BUCKET_NAME> --from-file=key=<PATH_TO_SERVICE_ACCOUNT_KEY> Note we store the desired bucket in the secret for brevity only, there are other ways to select a bucket.","title":"Secrets"},{"location":"static_provisioning/#usage","text":"Let's run an example application! kubectl apply -k \"github.com/ofek/csi-gcs/examples/static?ref=v0.9.0\" Confirm it's working by running kubectl get pods,pv,pvc You should see something like NAME READY STATUS RESTARTS AGE pod/csi-gcs-test-5f677df9f9-f59km 2/2 Running 0 10s NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/csi-gcs-pv 5Gi RWO Retain Bound default/csi-gcs-pvc csi-gcs-test-sc 10s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/csi-gcs-pvc Bound csi-gcs-pv 5Gi RWO csi-gcs-test-sc 10s Note the pod name, in this case csi-gcs-test-5f677df9f9-f59km . The pod in the example deployment has 2 containers: a writer and a reader . Now create some data! kubectl exec csi-gcs-test-5f677df9f9-f59km -c writer -- /bin/sh -c \"echo Hello from Google Cloud Storage! > /data/test.txt\" Let's read what we just put in the bucket $ kubectl exec csi-gcs-test-5f677df9f9-f59km -c reader -it -- /bin/sh / # ls -lh /data total 1K -rw-r--r-- 1 root root 33 May 26 21:23 test.txt / # cat /data/test.txt Hello from Google Cloud Storage! Notice that while the writer container's permission is completely governed by the service account key, the reader container is further restricted to read-only access / # touch /data/forbidden.txt touch: /data/forbidden.txt: Read-only file system To clean up everything, run the following commands kubectl delete -k \"github.com/ofek/csi-gcs/examples/static?ref=v0.9.0\" kubectl delete -k \"github.com/ofek/csi-gcs/deploy/overlays/stable?ref=v0.9.0\" kubectl delete secret csi-gcs-secret","title":"Usage"},{"location":"static_provisioning/#driver-options","text":"See the CSI section of the Kubernetes Volume docs .","title":"Driver options"},{"location":"static_provisioning/#service-account-key","text":"The contents of the JSON key may be passed in as a secret defined in PersistentVolume.spec.csi.nodePublishSecretRef . The name of the key in the secret is key . Tip You may omit the secret definition and let the code automatically detect the service account key using standard heuristics .","title":"Service account key"},{"location":"static_provisioning/#bucket","text":"The bucket name is resolved in the following order: bucket in PersistentVolume.spec.csi.volumeAttributes bucket in PersistentVolume.spec.mountOptions bucket in secret referenced by PersistentVolume.spec.csi.nodePublishSecretRef PersistentVolume.spec.csi.volumeHandle","title":"Bucket"},{"location":"static_provisioning/#extra-flags","text":"You can pass flags to gcsfuse in the following ways (ordered by precedence): PersistentVolume.spec.csi.volumeAttributes apiVersion : v1 kind : PersistentVolume spec : csi : driver : gcs.csi.ofek.dev volumeAttributes : gid : \"63147\" dirMode : \"0775\" fileMode : \"0664\" Option Type Description dirMode Octal Integer Permission bits for directories. (default: 0775) fileMode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful! PersistentVolume.spec.mountOptions apiVersion : v1 kind : PersistentVolume spec : mountOptions : - --gid=63147 - --dir-mode=0775 - --file-mode=0664 Option Type Description dir-mode Octal Integer Permission bits for directories. (default: 0775) file-mode Octal Integer Permission bits for files. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicit-dirs Flag Implicitly define directories based on content. billing-project Text Project to use for billing when accessing requester pays buckets. limit-bytes-per-sec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limit-ops-per-sec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. stat-cache-ttl Text How long to cache StatObject results and inode attributes e.g. 1h . type-cache-ttl Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuse-mount-option Text Additional comma-separated system-specific mount option . Be careful! PersistentVolume.spec.csi.nodePublishSecretRef Option Type Description dirMode Octal Integer Permission bits for directories, in octal. (default: 0775) fileMode Octal Integer Permission bits for files, in octal. (default: 0664) gid Integer GID owner of all inodes. (default: 63147) uid Integer UID owner of all inodes. (default: -1) implicitDirs Flag Implicitly define directories based on content. billingProject Text Project to use for billing when accessing requester pays buckets. limitBytesPerSec Integer Bandwidth limit for reading data, measured over a 30-second window. The default is -1 (no limit). limitOpsPerSec Integer Operations per second limit, measured over a 30-second window. The default is 5. Use -1 for no limit. statCacheTTL Text How long to cache StatObject results and inode attributes e.g. 1h . typeCacheTTL Text How long to cache name -> file/dir mappings in directory inodes e.g. 1h . fuseMountOptions Text[] Additional comma-separated system-specific mount options . Be careful!","title":"Extra flags"},{"location":"static_provisioning/#permission","text":"In order to access anything stored in GCS , you will need service accounts with appropriate IAM roles. If writes are needed, you will usually select roles/storage.objectAdmin scoped to the desired buckets. The easiest way to create service account keys, if you don't yet have any, is to run: gcloud iam service-accounts list to find the email of a desired service account, then run: gcloud iam service-accounts keys create <FILE_NAME>.json --iam-account <EMAIL> to create a key file.","title":"Permission"},{"location":"troubleshooting/","text":"Troubleshooting \u00b6 Early warnings from pods \u00b6 Warnings, like the one below, can be seen from pods scheduled on newly started nodes. MountVolume.MountDevice failed for volume \"xxxx\" : kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name gcs.csi.ofek.dev not found in the list of registered CSI drivers Those warnings are temporary and reflect that the driver is still starting. Kubernetes will retry until the driver is ready. The problem is often encountered in clusters with auto-scaler as nodes come and go. This is a known issue of kubernetes (see kubernetes#75890 ). A possible workaround is to taint all nodes running the csi-gcs driver like <driver name>/driver-ready=false:NoSchedule and use, as suggested in this comment , a custom controller like wish/nodetaint to remove the taint once the csi-gcs pod is ready. This workaround will ensure pods are repelled from nodes until the csi-gcs driver is ready without interfering with other components like the cluster auto-scaler. By default, <driver name> is gcs.csi.ofek.dev . Warning The driver labels the node with <driver name>/driver-ready=true to reflect its readiness state. It's possible to use a node selector to select nodes with a ready csi-gcs node driver. However, it doesn't work with clusters using cluster-autoscaler as the auto-scaler will never find a node with matching <driver name>/driver-ready=true label.","title":"Troubleshooting"},{"location":"troubleshooting/#early-warnings-from-pods","text":"Warnings, like the one below, can be seen from pods scheduled on newly started nodes. MountVolume.MountDevice failed for volume \"xxxx\" : kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name gcs.csi.ofek.dev not found in the list of registered CSI drivers Those warnings are temporary and reflect that the driver is still starting. Kubernetes will retry until the driver is ready. The problem is often encountered in clusters with auto-scaler as nodes come and go. This is a known issue of kubernetes (see kubernetes#75890 ). A possible workaround is to taint all nodes running the csi-gcs driver like <driver name>/driver-ready=false:NoSchedule and use, as suggested in this comment , a custom controller like wish/nodetaint to remove the taint once the csi-gcs pod is ready. This workaround will ensure pods are repelled from nodes until the csi-gcs driver is ready without interfering with other components like the cluster auto-scaler. By default, <driver name> is gcs.csi.ofek.dev . Warning The driver labels the node with <driver name>/driver-ready=true to reflect its readiness state. It's possible to use a node selector to select nodes with a ready csi-gcs node driver. However, it doesn't work with clusters using cluster-autoscaler as the auto-scaler will never find a node with matching <driver name>/driver-ready=true label.","title":"Early warnings from pods"},{"location":"contributing/authors/","text":"Authors \u00b6 Maintainers \u00b6 Ofek Lev Jonatan M\u00e4nnchen Contributors \u00b6 Ofek Lev Jonatan M\u00e4nnchen Joel Cressy Alex Khaerov","title":"Authors"},{"location":"contributing/authors/#maintainers","text":"Ofek Lev Jonatan M\u00e4nnchen","title":"Maintainers"},{"location":"contributing/authors/#contributors","text":"Ofek Lev Jonatan M\u00e4nnchen Joel Cressy Alex Khaerov","title":"Contributors"},{"location":"contributing/setup/","text":"Setup \u00b6 Getting started \u00b6 Dependencies You'll need to have Python 3.6+ in your PATH python -m pip install --upgrade -r requirements.txt Minikube Setup minikube Start minikube ( minikube start ) Build Enable minikube Docker Env ( eval $(minikube docker-env) ) Build Docker Image invoke image gcloud Install gcloud Login to gcloud ( gcloud auth login ) Google Cloud Project Create Test Project ( gcloud projects create [PROJECT_ID] --name=[PROJECT_NAME] ) Google Cloud Service Account Create ( gcloud iam service-accounts create [ACCOUNT_NAME] --display-name=\"Test Account\" --description=\"Test Account for GCS CSI\" --project=[PROJECT_ID] ) Create Key ( gcloud iam service-accounts keys create service-account.json --iam-account=[ACCOUNT_NAME]@[PROJECT_ID].iam.gserviceaccount.com --project=[PROJECT_ID] ) Give Storage Admin Permission ( gcloud projects add-iam-policy-binding [PROJECT_ID] --member=serviceAccount:[ACCOUNT_NAME]@[PROJECT_ID].iam.gserviceaccount.com --role=roles/storage.admin ) Create Secret kubectl create secret generic csi-gcs-secret --from-file=key=service-account.json Pull Needed Images docker pull quay.io/k8scsi/csi-node-driver-registrar:v1.2.0 Apply config kubectl apply -k deploy/overlays/dev Rebuild & Test Manually in Minikube \u00b6 # Build Binary invoke build # Build Container invoke image Afterwards kill the currently running pod. Documentation \u00b6 # Build invoke docs.build # Server invoke docs.serve Sanity Tests \u00b6 Needs root privileges and gcsfuse installed, execution via docker recommended. # Local invoke test.sanity # Docker invoke docker -c \"invoke test.sanity\" Additionally the file ./test/secret.yaml has to be created with the following content: CreateVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] DeleteVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] ControllerPublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] ControllerUnpublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] NodeStageVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Object Admin Key JSON] NodePublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Object Admin Key JSON] ControllerValidateVolumeCapabilitiesSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] Develop inside Docker \u00b6 Run all invoke commands through invoke env -c \"[CMD]\" . Regenerating the API Client \u00b6 If any changes are made in the pkg/apis package, the pkg/client needs to be regenerated. To regenerate the client package, run invoke codegen .","title":"Setup"},{"location":"contributing/setup/#getting-started","text":"Dependencies You'll need to have Python 3.6+ in your PATH python -m pip install --upgrade -r requirements.txt Minikube Setup minikube Start minikube ( minikube start ) Build Enable minikube Docker Env ( eval $(minikube docker-env) ) Build Docker Image invoke image gcloud Install gcloud Login to gcloud ( gcloud auth login ) Google Cloud Project Create Test Project ( gcloud projects create [PROJECT_ID] --name=[PROJECT_NAME] ) Google Cloud Service Account Create ( gcloud iam service-accounts create [ACCOUNT_NAME] --display-name=\"Test Account\" --description=\"Test Account for GCS CSI\" --project=[PROJECT_ID] ) Create Key ( gcloud iam service-accounts keys create service-account.json --iam-account=[ACCOUNT_NAME]@[PROJECT_ID].iam.gserviceaccount.com --project=[PROJECT_ID] ) Give Storage Admin Permission ( gcloud projects add-iam-policy-binding [PROJECT_ID] --member=serviceAccount:[ACCOUNT_NAME]@[PROJECT_ID].iam.gserviceaccount.com --role=roles/storage.admin ) Create Secret kubectl create secret generic csi-gcs-secret --from-file=key=service-account.json Pull Needed Images docker pull quay.io/k8scsi/csi-node-driver-registrar:v1.2.0 Apply config kubectl apply -k deploy/overlays/dev","title":"Getting started"},{"location":"contributing/setup/#rebuild-test-manually-in-minikube","text":"# Build Binary invoke build # Build Container invoke image Afterwards kill the currently running pod.","title":"Rebuild &amp; Test Manually in Minikube"},{"location":"contributing/setup/#documentation","text":"# Build invoke docs.build # Server invoke docs.serve","title":"Documentation"},{"location":"contributing/setup/#sanity-tests","text":"Needs root privileges and gcsfuse installed, execution via docker recommended. # Local invoke test.sanity # Docker invoke docker -c \"invoke test.sanity\" Additionally the file ./test/secret.yaml has to be created with the following content: CreateVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] DeleteVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] ControllerPublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] ControllerUnpublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON] NodeStageVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Object Admin Key JSON] NodePublishVolumeSecret: projectId: [Google Cloud Project ID] key: | [Storage Object Admin Key JSON] ControllerValidateVolumeCapabilitiesSecret: projectId: [Google Cloud Project ID] key: | [Storage Admin Key JSON]","title":"Sanity Tests"},{"location":"contributing/setup/#develop-inside-docker","text":"Run all invoke commands through invoke env -c \"[CMD]\" .","title":"Develop inside Docker"},{"location":"contributing/setup/#regenerating-the-api-client","text":"If any changes are made in the pkg/apis package, the pkg/client needs to be regenerated. To regenerate the client package, run invoke codegen .","title":"Regenerating the API Client"}]}